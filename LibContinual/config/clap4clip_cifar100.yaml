includes:
  - headers/data.yaml
  - headers/device.yaml
  - headers/model.yaml
  - headers/optimizer.yaml

device_ids: 0
n_gpu: 1
default_gpu: 0

# data
data_root: &data_root /root/autodl-tmp/ml_lab/data/cifar100/ # hlt's directory
# data_root: &data_root /root/autodl-tmp/cifar-100/cifar-100-dir/ # gyw's directory
image_size: &image_size 32
num_workers: 8
dataset: cifar100
save_path: ./


# training
init_cls_num: &init_cls_num 10
inc_cls_num: &inc_cls_num 10
total_cls_num: &total_cls_num 100
task_num: 10
warmup: 1
epoch: 5
val_per_epoch: 5 # according to num_test in parse_option()
train_batch_size: &train_batch_size 32
test_batch_size: 32
seed: 0

# optimizer
optimizer:
  name: SGD  # DONE: torch.optim.SGD(param_dict, lr=lr, weight_decay=self.wd)
  kwargs:
    lr: 1e-3
    # momentum: 0.9  # DONE: do not need momentum
    weight_decay: 0.0

# model
backbone:
  name: clip  
  kwargs: 
    model_name: ViT-B/16
    pretrained: True

buffer:
  name: LinearBuffer
  kwargs:
    buffer_size: 2000
    batch_size: *train_batch_size
    strategy: balance_random

# lr_scheduler:
#   name: CLAP4CLIPScheduler
#   kwargs:
#     lr: 1e-3

lr_scheduler:  # ref: add_a_new_method.md 
  name: MultiStepLR
  kwargs:
    gamma: 0.1
    milestones: [80, 120]

classifier: 
  name: CLAP4CLIP
  kwargs:
    # for LibContinual
    num_class: *total_cls_num
    init_cls_num: *init_cls_num
    inc_cls_num: *inc_cls_num
    feat_dim: 768  # 64

    # for CLAP4CLIP
    default_gpu: 0
    use_float32: False
    use_grad_checkpoint: False
    use_vga: True
    hierarchical: False
    train_batch_size:  *train_batch_size
    seed: 0 # todo: 两个seed用法一致吗？
    variational: True # 变分模式推理
    total_cls_num: *total_cls_num
    finetune: True
    distill: False
    expandable_tokens: False
    expandable_adapter: True
    expandable_prompt: False
    forward_times: 20
    forward_times_global: 10
    frozen_prior: False
    context_size: 0.67
    compute_ram: False
    use_np_prior: False
    lasp: True
    beta: 15.
    get_interclass_dist: False
    ortho_loss: False
    get_adapter_distances: False
    finetune_epochs: 2

    data_root: *data_root

    lr: 1e-3
    wd: 0.0


train_trfms:
  - Resize: 
      size: 224
      interpolation: BICUBIC
  - CenterCrop: 
      size: 224
  - Lambda:
      function: "lambda image: image.convert('RGB')"
  - RandomHorizontalFlip: {}
  - ToTensor: {}
  - Normalize:
      mean: [0.48145466, 0.4578275, 0.40821073]
      std: [0.26862954,0.26130258, 0.27577711]

test_trfms:
  - Resize: 
      size: 224
      interpolation: BICUBIC
  - CenterCrop: 
      size: 224
  - Lambda:
      function: "lambda image: image.convert('RGB')"
  - ToTensor: {}
  - Normalize:
      mean: [0.48145466, 0.4578275, 0.40821073]
      std: [0.26862954,0.26130258, 0.27577711]
